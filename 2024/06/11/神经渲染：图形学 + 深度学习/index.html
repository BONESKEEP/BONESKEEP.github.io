<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>神经渲染：图形学 + 深度学习 - BONESKEEP&#039; BLOG</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="BONESKEEP&#039; BLOG"><meta name="msapplication-TileImage" content="/img/headlogo.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="BONESKEEP&#039; BLOG"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="神经渲染：图形学 + 深度学习 利用深度学习和图形学技术，实现高质量、高效率、高灵活性的图像合成和渲染的方法，并且能够对图像进行编辑，从而实现多种应用，主要应用于影视动画、游戏开发、虚拟现实、自动驾驶等领域 原理 利用深度学习模型来模拟图形学渲染的过程，实现从输入到输出的端到端映射。 神经渲染是基于数据驱动和统计推断的概率模型，对场景中的信息进行隐式的表示和学习，通过大量的数据来模拟渲染过程； 传"><meta property="og:type" content="blog"><meta property="og:title" content="神经渲染：图形学 + 深度学习"><meta property="og:url" content="https://boneskeep.github.io/2024/06/11/%E7%A5%9E%E7%BB%8F%E6%B8%B2%E6%9F%93%EF%BC%9A%E5%9B%BE%E5%BD%A2%E5%AD%A6%20+%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"><meta property="og:site_name" content="BONESKEEP&#039; BLOG"><meta property="og:description" content="神经渲染：图形学 + 深度学习 利用深度学习和图形学技术，实现高质量、高效率、高灵活性的图像合成和渲染的方法，并且能够对图像进行编辑，从而实现多种应用，主要应用于影视动画、游戏开发、虚拟现实、自动驾驶等领域 原理 利用深度学习模型来模拟图形学渲染的过程，实现从输入到输出的端到端映射。 神经渲染是基于数据驱动和统计推断的概率模型，对场景中的信息进行隐式的表示和学习，通过大量的数据来模拟渲染过程； 传"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://boneskeep.github.io/img/og_image.png"><meta property="article:published_time" content="2024-06-11T08:00:00.000Z"><meta property="article:modified_time" content="2024-12-04T07:51:40.956Z"><meta property="article:author" content="BONESKEEP"><meta property="article:tag" content="学术"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="https://boneskeep.github.io/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://boneskeep.github.io/2024/06/11/%E7%A5%9E%E7%BB%8F%E6%B8%B2%E6%9F%93%EF%BC%9A%E5%9B%BE%E5%BD%A2%E5%AD%A6%20+%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},"headline":"神经渲染：图形学 + 深度学习","image":["https://boneskeep.github.io/img/og_image.png"],"datePublished":"2024-06-11T08:00:00.000Z","dateModified":"2024-12-04T07:51:40.956Z","author":{"@type":"Person","name":"BONESKEEP"},"publisher":{"@type":"Organization","name":"BONESKEEP' BLOG","logo":{"@type":"ImageObject","url":"https://boneskeep.github.io/img/head_circle.png"}},"description":"神经渲染：图形学 + 深度学习 利用深度学习和图形学技术，实现高质量、高效率、高灵活性的图像合成和渲染的方法，并且能够对图像进行编辑，从而实现多种应用，主要应用于影视动画、游戏开发、虚拟现实、自动驾驶等领域 原理 利用深度学习模型来模拟图形学渲染的过程，实现从输入到输出的端到端映射。 神经渲染是基于数据驱动和统计推断的概率模型，对场景中的信息进行隐式的表示和学习，通过大量的数据来模拟渲染过程； 传"}</script><link rel="canonical" href="https://boneskeep.github.io/2024/06/11/%E7%A5%9E%E7%BB%8F%E6%B8%B2%E6%9F%93%EF%BC%9A%E5%9B%BE%E5%BD%A2%E5%AD%A6%20+%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"><link rel="icon" href="/img/headlogo.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link data-pjax rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@11.7.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link data-pjax rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/head_circle.png" alt="BONESKEEP&#039; BLOG" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives/">Archives</a><a class="navbar-item" href="/categories/">Categories</a><a class="navbar-item" href="/tags/">Tags</a><a class="navbar-item" href="/about/">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="GitHub" href="https://github.com/BONESKEEP">GitHub</a><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/BONESKEEP/BONESKEEP.github.io"><i class="fab fa-github"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="目录" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2024-06-11T08:00:00.000Z" title="2024/6/11 16:00:00">2024-06-11</time>发表</span><span class="level-item"><time dateTime="2024-12-04T07:51:40.956Z" title="2024/12/4 15:51:40">2024-12-04</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/%E5%AD%A6%E6%9C%AF/">学术</a><span> / </span><a class="link-muted" href="/categories/%E5%AD%A6%E6%9C%AF/%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA/">三维重建</a></span><span class="level-item">31 分钟读完 (大约4606个字)</span></div></div><h1 class="title is-3 is-size-4-mobile">神经渲染：图形学 + 深度学习</h1><div class="content"><h3 id="神经渲染：图形学-深度学习"><a href="#神经渲染：图形学-深度学习" class="headerlink" title="神经渲染：图形学 + 深度学习"></a>神经渲染：图形学 + 深度学习</h3><hr>
<p>利用深度学习和图形学技术，实现高质量、高效率、高灵活性的图像合成和渲染的方法，并且能够对图像进行编辑，从而实现多种应用，主要应用于影视动画、游戏开发、虚拟现实、自动驾驶等领域</p>
<p><strong>原理</strong></p>
<p>利用深度学习模型来模拟图形学渲染的过程，实现从输入到输出的端到端映射。</p>
<p>神经渲染是基于数据驱动和统计推断的概率模型，对场景中的信息进行隐式的表示和学习，通过大量的数据来模拟渲染过程；</p>
<p>传统图形学渲染需要基于物理规律和数学模型的确定性算法，需要对场景中的几何、材质和光照等要素进行精确的描述和计算。</p>
<p><strong>主要流程</strong></p>
<p><strong>「空间表示」：</strong>指将三维空间中的信息以一种适合于深度学习模型处理的方式进行编码和存储。常见的空间表示方法有体素voxel、点云point cloud、网格mesh、隐函数implicit function等。</p>
<p><strong>「几何重建」：</strong>几何重建是指<strong>根据输入的二维图像或视频，恢复出三维空间中的几何结构</strong>。常见的几何重建方法有多视图立体（multi-view stereo）、结构光（structured light）、深度相机（depth camera）等。</p>
<p><strong>「光照模拟」：</strong>光照模拟是指<strong>根据输入或预设的光照条件，计算出三维空间中各个位置的光强度和颜色</strong>。常见的光照模拟方法有光线追踪（ray tracing）、光线投射（ray casting）、辐射度（radiosity）等。</p>
<p><strong>「视觉合成」：</strong>视觉合成是<strong>指根据给定或期望的视点位置</strong>，<strong>生成出对应视角下的二维图像或视频</strong>。常见的视觉合成方法有纹理映射（texture mapping）、着色器（shader）、后处理（post-processing）等。</p>
<p><strong>主要特点</strong></p>
<p><strong>「高质量」：</strong>生成高分辨率、高真实度、高一致性的图像，从而达到与真实世界或传统图形学渲染相媲美甚至超越的效果。</p>
<p><strong>「高效率」：</strong>利用深度学习模型的并行计算和近似推断的能力，大大降低图像合成和渲染的时间和空间复杂度。</p>
<p><strong>「高灵活性」：</strong>根据用户的需求和喜好，对图像进行多样化的操控、变换和编辑，实现个性化和创意化的图像生成。神经渲染的深度生成模型</p>
<p><strong>可能用到的模型</strong></p>
<p><strong>「变分自编码器（VAE）」：</strong>基于概率图模型的生成模型，由编码器和解码器两部分组成，编码器将输入数据映射到一个潜在空间中的随机变量，解码器将潜在变量映射回输出数据。通过最大化输入数据和输出数据之间的条件对数似然，以及最小化潜在变量和先验分布之间的散度，来学习数据的潜在分布和特征。可以用于神经渲染中的语义图像合成与操控，如根据用户给定的语义标签或草图，生成对应的真实图像，并且对图像中的内容进行添加、删除、移动、替换等操作。</p>
<p><strong>「生成对抗网络（GAN）」：</strong>基于博弈论的生成模型，由生成器和判别器两部分组成，生成器将随机噪声或条件输入映射到输出数据，判别器将输入数据判断为真实或伪造。通过最小化生成器和判别器之间的对抗损失，来学习数据的潜在分布和特征。可以用于神经渲染中的目标和场景的新视角合成，如根据用户给定的目标或场景的部分视角，生成其他视角下的图像，并且保持目标或场景的几何结构和光照条件不变。</p>
<p><strong>「自回归模型（AR）」：</strong>基于链式法则的生成模型，它将输出数据分解为一系列条件概率分布，每个分布依赖于之前生成的数据。通过最大化输出数据的联合对数似然，来学习数据的潜在分布和特征，用于神经渲染中的自由视点视频合成，如根据用户给定的视频序列，生成任意视点下的视频，并且保持视频中的动态物体和背景的运动和连贯性不变。</p>
<p><strong>图形学知识</strong></p>
<p><strong>「光线追踪」：</strong>基于物理光学原理的渲染技术，它通过模拟光线从视点出发，在三维空间中与物体表面发生反射、折射、散射等过程，从而计算出每个像素点的颜色和亮度。光线追踪可以用于神经渲染中提供真实感强烈的图像合成和渲染效果，以及提供对深度生成模型训练和推理过程中光照条件变化的约束和指导。</p>
<p><strong>「光照模型」：</strong>基于数学公式的渲染技术，它通过描述光源、物体表面和观察者之间的光照关系，从而计算出每个像素点的颜色和亮度。光照模型可以用于神经渲染中提供不同复杂度和效果的图像合成和渲染效果，以及提供对深度生成模型训练和推理过程中材质和纹理变化的约束和指导。</p>
<p><strong>「几何变换」：</strong>基于线性代数的渲染技术，它通过对三维空间中的物体进行平移、旋转、缩放等操作，从而改变物体的位置、方向和大小。几何变换可以用于神经渲染中提供不同视角和姿态的图像合成和渲染效果，以及提供对深度生成模型训练和推理过程中几何结构变化的约束和指导。</p>
<p><strong>光栅化</strong></p>
<p><strong>可能用到的端到端训练方式</strong></p>
<p><strong>「监督学习」：</strong>基于标注数据的训练方式，它通过给定输入数据和期望输出数据之间的对应关系，来训练深度生成模型。可以用于神经渲染中提供高质量和高精度的图像合成和渲染效果，但是需要大量的标注数据和计算资源。</p>
<p><strong>「无监督学习」：</strong>基于无标注数据的训练方式，它通过利用输入数据或输出数据本身的统计特征或结构信息，来训练深度生成模型。可以用于神经渲染中提供高效率和高灵活性的图像合成和渲染效果，但是需要复杂的模型设计和优化方法。</p>
<p><strong>「弱监督学习」：</strong>介于监督学习和无监督学习之间的训练方式，它通过利用输入数据或输出数据之间的部分或隐含的对应关系，来训练深度生成模型。可以用于神经渲染中提供高质量、高效率和高灵活性的图像合成和渲染效果，但是需要合适的先验知识和约束条件。</p>
<p><strong>神经渲染的应用领域</strong></p>
<ul>
<li><strong>语义图像合成与操控</strong>应用的例子</li>
</ul>
<p><strong>「SPADE」：</strong>基于GAN的语义图像合成方法，它通过使用空间自适应归一化（Spatially-Adaptive Normalization）层，将语义标签图作为生成器的输入，并在每个卷积层中根据语义标签图调整特征图的归一化参数，从而实现了对语义标签图中不同区域内容的精确控制。它能够根据用户给定的任意语义标签图，生成逼真且多样化的真实图像，并且能够对图像中的内容进行添加、删除、移动、替换等操作。</p>
<p><strong>「GauGAN」：</strong>基于SPADE改进的语义图像合成方法，它通过使用自注意力机制（Self-Attention Mechanism）和多尺度判别器（Multi-Scale Discriminator），增强了生成器的感知能力和判别器的区分能力，从而实现了对语义标签图中细节和全局的更好的生成和判断。它能够根据用户给定的任意草图，生成逼真且多样化的真实图像，并且能够对图像中的内容进行添加、删除、移动、替换等操作。</p>
<ul>
<li><strong>目标场景新视角合成</strong>应用的例子</li>
</ul>
<p><strong>「NeRF」：</strong>基于隐函数的新视角合成方法，它通过使用一个深度神经网络，将三维空间中的每个位置映射到一个颜色和不透明度的值，从而隐式地表示一个连续的三维场景。它能够根据用户给定的目标或场景的部分视角，生成其他视角下的图像，并且保持目标或场景的几何结构和光照条件不变。</p>
<p><strong>「NSVF」：</strong>基于体素的新视角合成方法，它通过使用一个稀疏体素网格，将三维空间中的每个体素映射到一个颜色和不透明度的值，从而显式地表示一个离散的三维场景。它能够根据用户给定的目标或场景的部分视角，生成其他视角下的图像，并且保持目标或场景的几何结构和光照条件不变。</p>
<ul>
<li><strong>自由视点视频合成</strong>应用的例子</li>
</ul>
<p><strong>「Neural Volumes」：</strong>基于体素和光场的自由视点视频合成方法，它通过使用一个时变体素网格，将三维空间中每个体素映射到一个颜色和不透明度的值，并且使用一个光场编码器，将每个体素进一步映射到一个光线方向相关的颜色和不透明度的值，从而表示一个动态且具有视差效果的三维场景。Neural Volumes能够根据用户给定的视频序列，生成任意视点下的视频，并且保持视频中的动态物体和背景的运动和连贯性不变。</p>
<p><strong>「Relightables」：</strong>基于神经网络和光场的学习重新打光方法，它通过使用一个神经网络，将三维空间中的每个位置映射到一个颜色和不透明度的值，并且使用一个光场编码器，将每个位置进一步映射到一个光照相关的颜色和不透明度的值，从而表示一个具有光照信息的三维场景。Relightables能够根据用户给定的目标或场景以及期望的光照条件，生成重新打光后的图像，并且保持目标或场景的材质和纹理不变。</p>
<p><strong>「Neural Relighting」：</strong>基于GAN和光照模型的学习重新打光方法，它通过使用一个生成器，将输入图像和期望的光照条件映射到输出图像，并且使用一个判别器，将输出图像和真实图像进行对比。Neural Relighting能够根据用户给定的目标或场景以及期望的光照条件，生成重新打光后的图像，并且保持目标或场景的材质和纹理不变。</p>
<ul>
<li><strong>人体重建渲染</strong>应用的例子</li>
</ul>
<p><strong>「Neural Body」：</strong>基于隐函数和自注意力机制的人体重建渲染方法，它通过使用一个时变隐函数，将三维空间中的每个位置映射到一个颜色和不透明度的值，并且使用一个自注意力机制，将每个位置进一步映射到一个视角相关的颜色和不透明度的值，从而表示一个动态且具有视差效果的人体模型。Neural Body能够根据用户给定的人体图片或视频，生成人体的三维模型，并且能够对人体进行姿态、表情、服装等属性的修改和变换。</p>
<p><strong>「Neural Human」：</strong>基于GAN和几何变换的人体重建渲染方法，它通过使用一个生成器，将输入图片或视频中的人体分割、关键点、姿态等信息映射到输出图片或视频，并且使用一个判别器，将输出图片或视频和真实图片或视频进行对比。Neural Human能够根据用户给定的人体图片或视频，生成人体的三维模型，并且能够对人体进行姿态、表情、服装等属性的修改和变换。</p>
<p><strong>神经渲染面临的挑战</strong></p>
<ul>
<li>技术上面临的挑战：</li>
</ul>
<p><strong>「真实性和一致性」：</strong>神经渲染需要生成与真实世界或传统图形学渲染相媲美甚至超越的图像合成和渲染效果，这需要深度生成模型能够捕捉到数据中的复杂和细微的特征和规律，以及图形学知识能够提供有效和准确的约束和指导。此外，神经渲染还需要保证在不同视角、光照、姿态等条件下，生成的图像具有一致性和连贯性，这需要深度生成模型能够处理数据中的多样性和变化性，以及图形学知识能够提供稳定和可靠的转换和映射。</p>
<p><strong>「复杂性和动态性」：</strong>神经渲染需要处理复杂和动态的场景，如多个物体、多种材质、多个光源、多个运动等，这需要深度生成模型能够表示和生成高维度和高分辨率的数据，以及图形学知识能够模拟和计算复杂的物理过程和效果。此外，神经渲染还需要适应用户的需求和喜好，对图像进行多样化的操控、变换和编辑，这需要深度生成模型能够响应和反馈用户的输入，以及图形学知识能够支持和实现用户的操作。</p>
<p><strong>「开销和资源」：</strong>神经渲染需要消耗大量的数据、计算、内存等资源，这需要深度生成模型能够有效地利用和优化资源的使用，以及图形学知识能够简化和加速资源的处理。此外，神经渲染还需要考虑用户的体验和满意度，对图像进行实时或近实时的合成和渲染，这需要深度生成模型能够快速地训练和推理，以及图形学知识能够并行地渲染和显示。</p>
<ul>
<li>应用上面临的挑战：</li>
</ul>
<p><strong>「质量和可信度」：</strong>神经渲染需要保证生成的图像具有高质量和高可信度，这需要对图像进行有效的评估和保证，如使用客观的指标和标准，如峰值信噪比（PSNR）、结构相似性（SSIM）、感知损失（Perceptual Loss）等，来衡量图像的真实性、一致性、清晰度等；或使用主观的方法和手段，如使用人类评估员或用户反馈，来衡量图像的美观性、满意度、偏好等。</p>
<p><strong>「需求和反馈」：</strong>神经渲染需要满足用户的需求和喜好，这需要对用户进行有效的分析和理解，如使用用户画像（User Profile）、用户行为（User Behavior）、用户情感（User Emotion）等，来获取用户的基本信息、兴趣爱好、情绪状态等；或使用用户交互（User Interaction）、用户反馈（User Feedback）、用户评价（User Evaluation）等，来获取用户的输入输出、意见建议、评分评价等。</p>
<p><strong>「隐私和版权」：</strong>神经渲染需要保护用户的隐私和版权，这需要对数据进行有效的管理和保护，如使用加密（Encryption）、哈希（Hashing）、水印（Watermarking）等，来防止数据被窃取、篡改、泄露等；或使用授权（Authorization）、认证（Authentication）、审计（Audit）等，来防止数据被滥用、侵权、盗用等。</p>
<p>神经渲染是一种将图形学与深度学习相结合的创新方法，它能够实现高质量、高效率、高灵活性的图像合成和渲染，也能够实现多种创意和应用，为图像处理和计算机视觉领域带来了新的可能性和挑战。神经渲染还有着广阔的发展前景和潜力，它可以与其他领域的技术和知识相结合，探索更多的应用场景和领域，促进社会和经济的进步和发展。</p>
</div><div class="article-licensing box"><div class="licensing-title"><p>神经渲染：图形学 + 深度学习</p><p><a href="https://boneskeep.github.io/2024/06/11/神经渲染：图形学 + 深度学习/">https://boneskeep.github.io/2024/06/11/神经渲染：图形学 + 深度学习/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>作者</h6><p>BONESKEEP</p></div></div><div class="level-item is-narrow"><div><h6>发布于</h6><p>2024-06-11</p></div></div><div class="level-item is-narrow"><div><h6>更新于</h6><p>2024-12-04</p></div></div><div class="level-item is-narrow"><div><h6>许可协议</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/%E5%AD%A6%E6%9C%AF/">学术</a></div><!--!--></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">喜欢这篇文章？打赏一下作者吧</h3><div class="buttons is-centered"><a class="button donate" data-type="wechat"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>微信</span><span class="qrcode"><img src="/img/wechat.jpg" alt="微信"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2024/06/11/NeRF%E5%85%A5%E9%97%A8%E5%8F%8A%E8%BF%9B%E9%98%B6%E2%80%94%E2%80%94%E4%B8%AD%E6%81%A9%E5%AE%9E%E9%AA%8C%E5%AE%A4/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">NeRF入门及进阶——中恩实验室</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2024/06/01/%E5%AD%A6%E6%9C%AF%E4%BA%A4%E6%B5%81%E4%BC%9A%202024.6.1/"><span class="level-item">医学AI学术交流会</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><!--!--></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/head_circle.png" alt="BONESKEEP"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">BONESKEEP</p><p class="is-size-6 is-block">硕士研究生</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Lanzhou University of Technology</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">46</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">14</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">6</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/BONESKEEP" target="_blank" rel="me noopener">关注我</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="me noopener" title="Github" href="https://github.com/BONESKEEP"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="me noopener" title="QQ" href="https://qm.qq.com/q/4kKCYBUmaA"><i class="fab fab fa-qq"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="me noopener" title="Mail" href="mailto:coolhui2020@163.com"><i class="fas fa-envelope"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="me noopener" title="Dribbble" href="https://dribbble.com"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="me noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">目录</h3><ul class="menu-list"><li><a class="level is-mobile" href="#神经渲染：图形学-深度学习"><span class="level-left"><span class="level-item">1</span><span class="level-item">神经渲染：图形学 + 深度学习</span></span></a></li></ul></div></div><style>#toc .menu-list > li > a.is-active + .menu-list { display: block; }#toc .menu-list > li > a + .menu-list { display: none; }</style><script src="/js/toc.js" defer></script></div><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">链接</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://github.com/BONESKEEP" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Github</span></span><span class="level-right"><span class="level-item tag">github.com</span></span></a></li><li><a class="level is-mobile" href="https://boneskeep.github.io/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Blog</span></span><span class="level-right"><span class="level-item tag">boneskeep.github.io</span></span></a></li></ul></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/Game/"><span class="level-start"><span class="level-item">Game</span></span><span class="level-end"><span class="level-item tag">2</span></span></a><ul><li><a class="level is-mobile" href="/categories/Game/Games101/"><span class="level-start"><span class="level-item">Games101</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Kunpeng/"><span class="level-start"><span class="level-item">Kunpeng</span></span><span class="level-end"><span class="level-item tag">5</span></span></a><ul><li><a class="level is-mobile" href="/categories/Kunpeng/Limb/"><span class="level-start"><span class="level-item">Limb</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Linux/"><span class="level-start"><span class="level-item">Linux</span></span><span class="level-end"><span class="level-item tag">28</span></span></a><ul><li><a class="level is-mobile" href="/categories/Linux/App/"><span class="level-start"><span class="level-item">App</span></span><span class="level-end"><span class="level-item tag">28</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Python/"><span class="level-start"><span class="level-item">Python</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E5%AD%A6%E6%9C%AF/"><span class="level-start"><span class="level-item">学术</span></span><span class="level-end"><span class="level-item tag">7</span></span></a><ul><li><a class="level is-mobile" href="/categories/%E5%AD%A6%E6%9C%AF/3DGS/"><span class="level-start"><span class="level-item">3DGS</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E5%AD%A6%E6%9C%AF/NeRF/"><span class="level-start"><span class="level-item">NeRF</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E5%AD%A6%E6%9C%AF/%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA/"><span class="level-start"><span class="level-item">三维重建</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E5%AD%A6%E6%9C%AF/%E5%91%BD%E4%BB%A4/"><span class="level-start"><span class="level-item">命令</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%E7%AE%97%E6%B3%95/"><span class="level-start"><span class="level-item">算法</span></span><span class="level-end"><span class="level-item tag">3</span></span></a><ul><li><a class="level is-mobile" href="/categories/%E7%AE%97%E6%B3%95/Leetcode/"><span class="level-start"><span class="level-item">Leetcode</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></li></ul></div></div></div><div class="column-right-shadow is-hidden-widescreen is-sticky"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3 is-sticky"><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">最新文章</h3><article class="media"><figure class="media-left"><a class="image" href="/2024/12/04/2024-12-04-Leetcode-Hot100-No.121-%E4%B9%B0%E5%8D%96%E8%82%A1%E7%A5%A8%E7%9A%84%E6%9C%80%E4%BD%B3%E6%97%B6%E6%9C%BA-%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"><img src="/img/leetcode/Shangri-La%20Frontier-01.jpg" alt="Leetcode Hot100 No.121 买卖股票的最佳时机 动态规划"></a></figure><div class="media-content"><p class="date"><time dateTime="2024-12-04T14:52:00.000Z">2024-12-04</time></p><p class="title"><a href="/2024/12/04/2024-12-04-Leetcode-Hot100-No.121-%E4%B9%B0%E5%8D%96%E8%82%A1%E7%A5%A8%E7%9A%84%E6%9C%80%E4%BD%B3%E6%97%B6%E6%9C%BA-%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/">Leetcode Hot100 No.121 买卖股票的最佳时机 动态规划</a></p><p class="categories"><a href="/categories/%E7%AE%97%E6%B3%95/">算法</a> / <a href="/categories/%E7%AE%97%E6%B3%95/Leetcode/">Leetcode</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2024/12/02/2024-12-04-Leetcode-Hot100-No.11-%E7%9B%9B%E6%9C%80%E5%A4%9A%E6%B0%B4%E7%9A%84%E5%AE%B9%E5%99%A8/"><img src="/img/leetcode/Shangri-La%20Frontier-01.jpg" alt="Leetcode Hot100 No.11 盛最多水的容器"></a></figure><div class="media-content"><p class="date"><time dateTime="2024-12-02T14:52:00.000Z">2024-12-02</time></p><p class="title"><a href="/2024/12/02/2024-12-04-Leetcode-Hot100-No.11-%E7%9B%9B%E6%9C%80%E5%A4%9A%E6%B0%B4%E7%9A%84%E5%AE%B9%E5%99%A8/">Leetcode Hot100 No.11 盛最多水的容器</a></p><p class="categories"><a href="/categories/%E7%AE%97%E6%B3%95/">算法</a> / <a href="/categories/%E7%AE%97%E6%B3%95/Leetcode/">Leetcode</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-10-31T10:18:00.000Z">2024-10-31</time></p><p class="title"><a href="/2024/10/31/linux_11_input_05_input_read_fasync/">linux_11_input_05_input_read_fasync</a></p><p class="categories"><a href="/categories/Linux/">Linux</a> / <a href="/categories/Linux/App/">App</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-10-31T07:41:00.000Z">2024-10-31</time></p><p class="title"><a href="/2024/10/31/linux_11_input_03_input_read_poll_more/">linux_11_input_03_input_read_poll_more</a></p><p class="categories"><a href="/categories/Linux/">Linux</a> / <a href="/categories/Linux/App/">App</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-10-31T07:40:00.000Z">2024-10-31</time></p><p class="title"><a href="/2024/10/31/linux_11_input_03_input_read_poll/">linux_11_input_03_input_read_poll</a></p><p class="categories"><a href="/categories/Linux/">Linux</a> / <a href="/categories/Linux/App/">App</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">归档</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2024/12/"><span class="level-start"><span class="level-item">十二月 2024</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/10/"><span class="level-start"><span class="level-item">十月 2024</span></span><span class="level-end"><span class="level-item tag">29</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/09/"><span class="level-start"><span class="level-item">九月 2024</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/06/"><span class="level-start"><span class="level-item">六月 2024</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/03/"><span class="level-start"><span class="level-item">三月 2024</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/12/"><span class="level-start"><span class="level-item">十二月 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/10/"><span class="level-start"><span class="level-item">十月 2023</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/09/"><span class="level-start"><span class="level-item">九月 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/04/"><span class="level-start"><span class="level-item">四月 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">标签</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/Games101/"><span class="tag">Games101</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Kunpeng/"><span class="tag">Kunpeng</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Leetcode/"><span class="tag">Leetcode</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Linux/"><span class="tag">Linux</span><span class="tag">28</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Python/"><span class="tag">Python</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%AD%A6%E6%9C%AF/"><span class="tag">学术</span><span class="tag">7</span></a></div></div></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/head_circle.png" alt="BONESKEEP&#039; BLOG" height="28"></a><p class="is-size-7"><span>&copy; 2024 BONESKEEP</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p><p class="is-size-7">Open Source</p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-cn");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script data-pjax src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script data-pjax src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pjax@0.2.8/pjax.min.js"></script><script src="/js/pjax.js"></script><!--!--><!--!--><!--!--><script data-pjax src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>